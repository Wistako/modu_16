{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from prettytable import PrettyTable\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_check(model, Xtrain, Xtest, ytrain, ytest):\n",
    "    classifier = model\n",
    "    start = datetime.datetime.now()\n",
    "    classifier.fit(Xtrain, ytrain)\n",
    "    end = datetime.datetime.now()\n",
    "    time = (end - start).microseconds\n",
    "    evaluation = np.round(classifier.score(Xtest, ytest), 4)\n",
    "    return evaluation, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (584, 10), y_train.shape: (584,)\n",
      "X_test.shape: (147, 10), y_test.shape: (147,)\n",
      "+-------------------------+------------+--------------------------------+\n",
      "|          Model          | Dokładność | Czas trenowania (microseconds) |\n",
      "+-------------------------+------------+--------------------------------+\n",
      "| Nieskalowane dane - KNN |   0.504    |              3091              |\n",
      "|   Skalowane dane - KNN  |   0.6026   |              998               |\n",
      "|        9 PC - KNN       |   0.5949   |              1947              |\n",
      "|        8 PC - KNN       |   0.5066   |              1994              |\n",
      "|        7 PC - KNN       |   0.4901   |              1957              |\n",
      "|        6 PC - KNN       |   0.4856   |              997               |\n",
      "|        5 PC - KNN       |   0.2237   |               0                |\n",
      "|        4 PC - KNN       |   0.2846   |               0                |\n",
      "|        3 PC - KNN       |   -0.164   |               0                |\n",
      "|        2 PC - KNN       |  -0.4771   |               0                |\n",
      "|        1 PC - KNN       |   -1.286   |               0                |\n",
      "+-------------------------+------------+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('daily-bike-share.csv', parse_dates=['dteday'])\n",
    "data.drop(columns=['instant', 'dteday', 'yr'], inplace=True)\n",
    "y = data['rentals']\n",
    "numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "categorical_features = ['season','mnth','holiday','weekday','workingday','weathersit']\n",
    "\n",
    "data['difference_temp'] = (data['atemp'] - data['temp']) / data['temp']\n",
    "data.drop(columns=['atemp'], axis=1, inplace=True)\n",
    "numeric_features = ['temp', 'difference_temp', 'hum', 'windspeed']\n",
    "\n",
    "X = pd.get_dummies(data[numeric_features + categorical_features])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "print(f\"X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "y_test.value_counts()\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=1)\n",
    "\n",
    "results = PrettyTable(['Model',\n",
    "                       'Dokładność',\n",
    "                       'Czas trenowania (microseconds)'])\n",
    "\n",
    "# Trenowanie modelu na nieprzetworzonym zbiorze\n",
    "not_scaled_data = train_and_check(knn, X_train, X_test, y_train, y_test)\n",
    "results.add_row(['Nieskalowane dane - KNN', not_scaled_data[0], not_scaled_data[1]])\n",
    "\n",
    "# Trenowanie modelu na przetworzonym zbiorze\n",
    "scaled_data = train_and_check(knn, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "results.add_row(['Skalowane dane - KNN', scaled_data[0], scaled_data[1]])\n",
    "\n",
    "# Trenowanie modelu na czterech Głównych Składowych\n",
    "PC9_data = train_and_check(knn, X_train_pca[:,:9], X_test_pca[:,:9], y_train, y_test)\n",
    "results.add_row(['9 PC - KNN', PC9_data[0], PC9_data[1]])\n",
    "\n",
    "# Trenowanie modelu na czterech Głównych Składowych\n",
    "PC4_data = train_and_check(knn, X_train_pca[:,:8], X_test_pca[:,:8], y_train, y_test)\n",
    "results.add_row(['8 PC - KNN', PC4_data[0], PC4_data[1]])\n",
    "\n",
    "# Trenowanie modelu na czterech Głównych Składowych\n",
    "PC4_data = train_and_check(knn, X_train_pca[:,:7], X_test_pca[:,:7], y_train, y_test)\n",
    "results.add_row(['7 PC - KNN', PC4_data[0], PC4_data[1]])\n",
    "\n",
    "# Trenowanie modelu na czterech Głównych Składowych\n",
    "PC4_data = train_and_check(knn, X_train_pca[:,:6], X_test_pca[:,:6], y_train, y_test)\n",
    "results.add_row(['6 PC - KNN', PC4_data[0], PC4_data[1]])\n",
    "\n",
    "# Trenowanie modelu na czterech Głównych Składowych\n",
    "PC4_data = train_and_check(knn, X_train_pca[:,:5], X_test_pca[:,:5], y_train, y_test)\n",
    "results.add_row(['5 PC - KNN', PC4_data[0], PC4_data[1]])\n",
    "\n",
    "# Trenowanie modelu na czterech Głównych Składowych\n",
    "PC4_data = train_and_check(knn, X_train_pca[:,:4], X_test_pca[:,:4], y_train, y_test)\n",
    "results.add_row(['4 PC - KNN', PC4_data[0], PC4_data[1]])\n",
    "\n",
    "# Trenowanie modelu na trzech Głównych Składowych\n",
    "PC3_data = train_and_check(knn, X_train_pca[:, :3], X_test_pca[:, :3], y_train, y_test)\n",
    "results.add_row(['3 PC - KNN', PC3_data[0], PC3_data[1]])\n",
    "\n",
    "# Trenowanie modelu na dwóch Głównych Składowych\n",
    "PC2_data = train_and_check(knn, X_train_pca[:, :2], X_test_pca[:, :2], y_train, y_test)\n",
    "results.add_row(['2 PC - KNN', PC2_data[0], PC2_data[1]])\n",
    "\n",
    "# Trenowanie modelu na jednej Głównej Składowej\n",
    "PC1_data = train_and_check(knn, X_train_pca[:, :1], X_test_pca[:, :1],  y_train, y_test)\n",
    "results.add_row(['1 PC - KNN', PC1_data[0], PC1_data[1]])\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
